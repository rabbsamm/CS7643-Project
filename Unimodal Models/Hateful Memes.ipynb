{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2482bce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoFeatureExtractor, CvtForImageClassification, AutoTokenizer, RobertaModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from string import digits\n",
    "from html import unescape\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchmetrics.functional.classification import auroc, accuracy\n",
    "\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import os\n",
    "import pytorch_lightning as pl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "accd525c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\rabby\\CS 7643 - Deep Learning\\Project')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "config = {\n",
    "    'vmodel_name': 'microsoft/cvt-21',\n",
    "    'vmodel_path': r'C:\\Users\\rabby\\CS 7643 - Deep Learning\\Project\\Unimodal Models\\Finetuned_CvT.pth.tar',\n",
    "    'tmodel_name': 'roberta-base',\n",
    "    'tmodel_path': r'C:\\Users\\rabby\\CS 7643 - Deep Learning\\Project\\Unimodal Models\\Finetuned_Roberta.pth.tar',\n",
    "    'n_labels': 2,\n",
    "    'batch_size': 32,\n",
    "    'dropout': 0.25,\n",
    "    'hidden_size': 512,\n",
    "    'lr': 5e-5,\n",
    "    'n_epochs': 10,\n",
    "    'device': device,\n",
    "    'n_img_train': 8500,\n",
    "    'n_img_val': 500,\n",
    "    'img_train': r'C:\\Users\\rabby\\CS 7643 - Deep Learning\\Project\\Data\\img_preprocessed',\n",
    "    'img_val': r'C:\\Users\\rabby\\CS 7643 - Deep Learning\\Project\\Data\\img_preprocessed',\n",
    "    'label_train':r'C:\\Users\\rabby\\CS 7643 - Deep Learning\\Project\\Data\\hateful_memes\\train.jsonl',\n",
    "    'label_val': r'C:\\Users\\rabby\\CS 7643 - Deep Learning\\Project\\Data\\hateful_memes\\dev_seen.jsonl',\n",
    "    'reload': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccac0da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Load_Memes(config):\n",
    "    #Load Extractor\n",
    "    extractor = AutoFeatureExtractor.from_pretrained(config['vmodel_name'])\n",
    "    #Load Train Data\n",
    "    n = 0\n",
    "    label_train = pd.read_json(config['label_train'], lines = True, nrows = config['n_img_train'])\n",
    "    img_train_id = list(label_train['id'].values)\n",
    "    img_train_list = [config['img_train'] + r'\\\\' + str(i).zfill(5) + '.png' for i in img_train_id]\n",
    "    for img_path in img_train_list:\n",
    "        if n == 0:\n",
    "            img_train = torch.tensor(extractor(torchvision.io.read_image(img_path), return_tensors=\"pt\")['pixel_values'][0])\n",
    "            print('Training Image', str(n), 'loaded.')\n",
    "        else:\n",
    "            img_train = torch.cat((img_train.view(n, 3, 224, 224), torch.tensor(extractor(torchvision.io.read_image(img_path), return_tensors=\"pt\")['pixel_values'][0]).view(1, 3, 224, 224)))\n",
    "        n += 1\n",
    "        if (n % 1000 == 0):\n",
    "            print('Training Image', str(n), 'loaded.')\n",
    "    \n",
    "    text_train = list(label_train['text'].values)\n",
    "    print('Training Text', str(config['n_img_train']), 'loaded.')\n",
    "    \n",
    "    labels_train = list(label_train['label'].values)\n",
    "    print('Training Label', str(config['n_img_train']), 'loaded.')\n",
    "    \n",
    "    n = 0\n",
    "    label_val = pd.read_json(config['label_val'], lines = True, nrows = config['n_img_val'])\n",
    "    img_val_id = list(label_val['id'].values)\n",
    "    img_val_list = [config['img_val'] + r'\\\\' + str(i).zfill(5) + '.png' for i in img_val_id]\n",
    "    for img_path in img_val_list:\n",
    "        if n == 0:\n",
    "            img_val = torch.tensor(extractor(torchvision.io.read_image(img_path), return_tensors=\"pt\")['pixel_values'][0])\n",
    "            print('Validation Image', str(n), 'loaded.')\n",
    "        else:\n",
    "            img_val = torch.cat((img_val.view(n, 3, 224, 224), torch.tensor(extractor(torchvision.io.read_image(img_path), return_tensors=\"pt\")['pixel_values'][0]).view(1, 3, 224, 224)))\n",
    "        n += 1\n",
    "        if (n % 1000 == 0):\n",
    "            print('Validation Image', str(n), 'loaded.')\n",
    "    \n",
    "    text_val = list(label_val['text'].values)\n",
    "    print('Validation Text', str(config['n_img_val']), 'loaded.')\n",
    "    \n",
    "    labels_val = list(label_val['label'].values)\n",
    "    print('Validation Label', str(config['n_img_val']), 'loaded.')\n",
    "    \n",
    "    return img_train, text_train, labels_train, img_val, text_val, labels_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1c3adee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memes_Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, image, text, label, tokenizer, max_length = 128):\n",
    "        #Declare variables\n",
    "        self.image = image\n",
    "        self.text = text\n",
    "        self.labels = torch.tensor(label)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        meme_text = self.text[index]\n",
    "        tokens = self.tokenizer.encode_plus(meme_text, add_special_tokens = True, return_tensors = 'pt', truncation = True, \n",
    "                                           max_length = self.max_length, padding = 'max_length', return_attention_mask = True)\n",
    "        \n",
    "        return {'image': self.image[index], 'input_ids': tokens.input_ids.flatten(), \n",
    "                'attention_mask': tokens.attention_mask.flatten(), 'labels': self.labels[index]}\n",
    "    \n",
    "class Memes_Data_Module(pl.LightningDataModule):\n",
    "    \n",
    "    def __init__(self, train_image, train_text, train_labels, \n",
    "                 val_image, val_text, val_labels, \n",
    "                 test_image = None, test_text = None, test_labels = None, \n",
    "                 batch_size = 16, max_length = 128, text_model = 'roberta-base'):\n",
    "        super().__init__()\n",
    "        self.train_img = train_image\n",
    "        self.train_text = train_text\n",
    "        self.train_labels = train_labels\n",
    "        self.val_img = val_image\n",
    "        self.val_text = val_text\n",
    "        self.val_labels = val_labels\n",
    "        if test_image == None:\n",
    "            self.test_img = val_image\n",
    "            self.test_text = val_text\n",
    "            self.test_labels = val_labels\n",
    "        else:\n",
    "            self.test_img = test_image\n",
    "            self.test_text = test_text\n",
    "            self.text_labels = test_labels\n",
    "        self.batch_size = batch_size\n",
    "        self.max_length = max_length\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(text_model)\n",
    "        \n",
    "    def setup(self, stage = None):\n",
    "        self.train_ds = Memes_Dataset(self.train_img, self.train_text, self.train_labels, \n",
    "                                      self.tokenizer, max_length = self.max_length)\n",
    "        self.val_ds = Memes_Dataset(self.val_img, self.val_text, self.val_labels, \n",
    "                                    self.tokenizer, max_length = self.max_length)\n",
    "        self.test_ds = Memes_Dataset(self.test_img, self.test_text, self.test_labels,\n",
    "                                    self.tokenizer, max_length = self.max_length)\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_ds, batch_size = self.batch_size, shuffle = True)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_ds, batch_size = self.batch_size, shuffle = False)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_ds, batch_size = self.batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8c243d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVT_Fairface(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.feature_extractor = AutoFeatureExtractor.from_pretrained(config['model_name'])\n",
    "        self.model = CvtForImageClassification.from_pretrained(config['model_name']).to(device)\n",
    "        self.new_classifier = nn.Linear(384, self.config['n_labels']).to(device)\n",
    "        torch.nn.init.xavier_uniform_(self.new_classifier.weight)\n",
    "        self.model.classifier = self.new_classifier\n",
    "        self.softmax = nn.Softmax(dim = 1)\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        self.training_step_outputs = []\n",
    "        self.training_auroc = []\n",
    "        self.training_acc = []\n",
    "        self.validation_step_outputs = []\n",
    "        self.validation_auroc = []\n",
    "        self.validation_acc = []\n",
    "        self.test_step_outputs = []\n",
    "        self.test_auroc = []\n",
    "        self.test_acc = []\n",
    "        self.tloss = []\n",
    "        self.tauroc = []\n",
    "        self.tacc = []\n",
    "        self.vloss = []\n",
    "        self.vauroc = []\n",
    "        self.vacc = []\n",
    "           \n",
    "    def forward(self, x, labels = None):\n",
    "        features = x.to(self.config['device'])\n",
    "        out = self.model(features)\n",
    "        return out.logits\n",
    "    \n",
    "    def training_step(self, batch, batch_index):\n",
    "        loss, out, y = self._common_step(batch, batch_index)\n",
    "        pred = self.softmax(out)\n",
    "        t_auroc = auroc(pred, y, task = 'multiclass', num_classes = self.config['n_labels'])\n",
    "        t_acc = accuracy(pred, y, task = 'multiclass', num_classes = self.config['n_labels'])\n",
    "        self.training_step_outputs.append(loss)\n",
    "        self.training_auroc.append(t_auroc)\n",
    "        self.training_acc.append(t_acc)\n",
    "        self.log(\"Training Accuracy\", t_acc, prog_bar = True, logger = True)\n",
    "        return loss\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        epoch_mean = torch.stack(self.training_step_outputs).mean()\n",
    "        epoch_auroc = torch.stack(self.training_auroc).mean()\n",
    "        epoch_acc = torch.stack(self.training_acc).mean()\n",
    "        self.tloss.append(float(epoch_mean.detach().cpu().numpy()))\n",
    "        self.tauroc.append(float(epoch_auroc.detach().cpu().numpy()))\n",
    "        self.tacc.append(float(epoch_acc.detach().cpu().numpy()))\n",
    "        self.training_step_outputs.clear()\n",
    "        self.training_auroc.clear()\n",
    "        self.training_acc.clear()\n",
    "    \n",
    "    def validation_step(self, batch, batch_index):\n",
    "        loss, out, y = self._common_step(batch, batch_index)\n",
    "        pred = self.softmax(out)\n",
    "        v_auroc = auroc(pred, y, task = 'multiclass', num_classes = self.config['n_labels'])\n",
    "        v_acc = accuracy(pred, y, task = 'multiclass', num_classes = self.config['n_labels'])\n",
    "        self.validation_step_outputs.append(loss)\n",
    "        self.validation_auroc.append(v_auroc)\n",
    "        self.validation_acc.append(v_acc)\n",
    "        self.log(\"Validation Accuracy\", v_acc, prog_bar = True, logger = True)\n",
    "        return loss\n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        epoch_mean = torch.stack(self.validation_step_outputs).mean()\n",
    "        epoch_auroc = torch.stack(self.validation_auroc).mean()\n",
    "        epoch_acc = torch.stack(self.validation_acc).mean()\n",
    "        self.vloss.append(float(epoch_mean.detach().cpu().numpy()))\n",
    "        self.vauroc.append(float(epoch_auroc.detach().cpu().numpy()))\n",
    "        self.vacc.append(float(epoch_acc.detach().cpu().numpy()))\n",
    "        self.validation_step_outputs.clear()\n",
    "        self.validation_auroc.clear()\n",
    "        self.validation_acc.clear()\n",
    "    \n",
    "    def test_step(self, batch, batch_index):\n",
    "        loss, out, y = self._common_step(batch, batch_index)\n",
    "        pred = self.softmax(out)\n",
    "        t_auroc = auroc(pred, y, task = 'multiclass', num_classes = self.config['n_labels'])\n",
    "        t_acc = accuracy(pred, y, task = 'multiclass', num_classes = self.config['n_labels'])\n",
    "        self.test_step_outputs.append(loss)\n",
    "        self.test_auroc.append(t_auroc)\n",
    "        self.test_acc.append(t_acc)\n",
    "        self.log(\"Test Accuracy\", t_acc, prog_bar = True, logger = True)\n",
    "        return loss\n",
    "\n",
    "    def predict_step(self, batch, batch_index):\n",
    "        loss, out, y = self._common_step(batch, batch_index)\n",
    "        return loss\n",
    "    \n",
    "    def _common_step(self, batch, batch_index):\n",
    "        x, y = batch\n",
    "        x = x.type(torch.cuda.FloatTensor)\n",
    "        y = y.type(torch.LongTensor)\n",
    "        y = y.to(config['device'])\n",
    "        out = self.forward(x)\n",
    "        loss = self.loss(out, y)\n",
    "        return loss, out, y\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr = self.config['lr'])\n",
    "        return [optimizer]\n",
    "    \n",
    "    def plot_loss(self):\n",
    "        self.vloss.pop()\n",
    "        plt.plot(self.tloss, label = 'Training')\n",
    "        plt.plot(self.vloss, label = 'Validation')\n",
    "        plt.title('Loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    def plot_auroc(self):\n",
    "        self.vauroc.pop()\n",
    "        plt.plot(self.tauroc, label = 'Training')\n",
    "        plt.plot(self.vauroc, label = 'Validation')\n",
    "        plt.title('AUROC')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    def plot_accuracy(self):\n",
    "        self.vacc.pop()\n",
    "        plt.plot(self.tacc, label = 'Training')\n",
    "        plt.plot(self.vacc, label = 'Validation')\n",
    "        plt.title('Accuracy')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e51f546",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Roberta_Pol(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.model = AutoModel.from_pretrained(config['model_name'], return_dict = True)\n",
    "        self.classifier = nn.Linear(self.model.config.hidden_size, self.config['n_labels'])\n",
    "        self.softmax = nn.Softmax(dim = 1)\n",
    "        self.loss = nn.MSELoss()\n",
    "        self.training_step_outputs = []\n",
    "        self.validation_step_outputs = []\n",
    "        self.tloss = []\n",
    "        self.vloss = []\n",
    "           \n",
    "    def forward(self, input_ids, attention_mask, labels = None):\n",
    "        out = self.model(input_ids = input_ids, attention_mask = attention_mask)\n",
    "        out = torch.mean(out.last_hidden_state, 1)\n",
    "        # final logits\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "    \n",
    "    def training_step(self, batch, batch_index):\n",
    "        loss, out, y = self._common_step(batch, batch_index)\n",
    "        self.training_step_outputs.append(loss)\n",
    "        self.log(\"Training Loss\", loss, prog_bar = True, logger = True)\n",
    "        return loss\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        epoch_mean = torch.stack(self.training_step_outputs).mean()\n",
    "        self.tloss.append(float(epoch_mean.detach().cpu().numpy()))\n",
    "        self.training_step_outputs.clear()\n",
    "    \n",
    "    def validation_step(self, batch, batch_index):\n",
    "        loss, out, y = self._common_step(batch, batch_index)\n",
    "        self.validation_step_outputs.append(loss)\n",
    "        self.log(\"Validation Loss\", loss, prog_bar = True, logger = True)\n",
    "        return loss\n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        epoch_mean = torch.stack(self.validation_step_outputs).mean()\n",
    "        self.vloss.append(float(epoch_mean.detach().cpu().numpy()))\n",
    "        self.validation_step_outputs.clear()\n",
    "    \n",
    "    def test_step(self, batch, batch_index):\n",
    "        loss, out, y = self._common_step(batch, batch_index)\n",
    "        self.log(\"Test Loss\", loss, prog_bar = True, logger = True)\n",
    "        return loss\n",
    "\n",
    "    def predict_step(self, batch, batch_index):\n",
    "        loss, out, y = self._common_step(batch, batch_index)\n",
    "        return loss\n",
    "    \n",
    "    def _common_step(self, batch, batch_index):\n",
    "        x = batch['input_ids']\n",
    "        y = batch['labels'].squeeze(1)\n",
    "        attn_mask = batch['attention_mask']\n",
    "        out = self.forward(x, attn_mask)\n",
    "        y = y.to(config['device'])\n",
    "        loss = self.loss(out, y)\n",
    "        return loss, out, y\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr = self.config['lr'])\n",
    "        return [optimizer]\n",
    "    \n",
    "    def plot_loss(self):\n",
    "        self.vloss.pop()\n",
    "        plt.plot(self.tloss, label = 'Training')\n",
    "        plt.plot(self.vloss, label = 'Validation')\n",
    "        plt.title('Loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    def plot_auroc(self):\n",
    "        self.vauroc.pop()\n",
    "        plt.plot(self.tauroc, label = 'Training')\n",
    "        plt.plot(self.vauroc, label = 'Validation')\n",
    "        plt.title('AUROC')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    def plot_accuracy(self):\n",
    "        self.vacc.pop()\n",
    "        plt.plot(self.tacc, label = 'Training')\n",
    "        plt.plot(self.vacc, label = 'Validation')\n",
    "        plt.title('Accuracy')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bde8488",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVT_Roberta(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.cvt = torch.load(config['vmodel_path'])\n",
    "        self.roberta = torch.load(config['tmodel_path'])\n",
    "        self.linear_cvt = nn.Linear(384, self.config['hidden_size'])\n",
    "        self.linear_roberta = nn.Linear(self.roberta.model.config.hidden_size, self.config['hidden_size'])\n",
    "        #self.classifier = nn.Linear(2 * self.config['hidden_size'], config['n_labels'])\n",
    "        self.classifier = nn.Sequential(nn.Linear(2 * self.config['hidden_size'], 2 * self.config['hidden_size']),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.Dropout(config['dropout']),\n",
    "                                       nn.Linear(2 * self.config['hidden_size'], self.config['n_labels']))\n",
    "        self.cvt.model.classifier = self.linear_cvt\n",
    "        self.roberta.classifier = self.linear_roberta\n",
    "        self.softmax = nn.Softmax(dim = 1)\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        self.training_step_outputs = []\n",
    "        self.training_auroc = []\n",
    "        self.training_acc = []\n",
    "        self.validation_step_outputs = []\n",
    "        self.validation_auroc = []\n",
    "        self.validation_acc = []\n",
    "        self.test_step_outputs = []\n",
    "        self.test_auroc = []\n",
    "        self.test_acc = []\n",
    "        self.tloss = []\n",
    "        self.tauroc = []\n",
    "        self.tacc = []\n",
    "        self.vloss = []\n",
    "        self.vauroc = []\n",
    "        self.vacc = []\n",
    "        \n",
    "    def forward(self, img, text, attn_mask, labels = None):\n",
    "        img = torch.squeeze(img)\n",
    "        v_out = self.cvt(img)\n",
    "        t_out = self.roberta(text, attn_mask)\n",
    "        out = torch.cat((v_out, t_out), dim = 1)\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "    \n",
    "    def training_step(self, batch, batch_index):\n",
    "        loss, out, y = self._common_step(batch, batch_index)\n",
    "        pred = self.softmax(out)\n",
    "        t_auroc = auroc(pred, y, task = 'multiclass', num_classes = self.config['n_labels'])\n",
    "        t_acc = accuracy(pred, y, task = 'multiclass', num_classes = self.config['n_labels'])\n",
    "        self.training_step_outputs.append(loss)\n",
    "        self.training_auroc.append(t_auroc)\n",
    "        self.training_acc.append(t_acc)\n",
    "        self.log(\"Training Accuracy\", t_acc, prog_bar = True, logger = True)\n",
    "        return loss\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        epoch_mean = torch.stack(self.training_step_outputs).mean()\n",
    "        epoch_auroc = torch.stack(self.training_auroc).mean()\n",
    "        epoch_acc = torch.stack(self.training_acc).mean()\n",
    "        self.tloss.append(float(epoch_mean.detach().cpu().numpy()))\n",
    "        self.tauroc.append(float(epoch_auroc.detach().cpu().numpy()))\n",
    "        self.tacc.append(float(epoch_acc.detach().cpu().numpy()))\n",
    "        self.training_step_outputs.clear()\n",
    "        self.training_auroc.clear()\n",
    "        self.training_acc.clear()\n",
    "    \n",
    "    def validation_step(self, batch, batch_index):\n",
    "        loss, out, y = self._common_step(batch, batch_index)\n",
    "        pred = self.softmax(out)\n",
    "        v_auroc = auroc(pred, y, task = 'multiclass', num_classes = self.config['n_labels'])\n",
    "        v_acc = accuracy(pred, y, task = 'multiclass', num_classes = self.config['n_labels'])\n",
    "        self.validation_step_outputs.append(loss)\n",
    "        self.validation_auroc.append(v_auroc)\n",
    "        self.validation_acc.append(v_acc)\n",
    "        self.log(\"Validation Accuracy\", v_acc, prog_bar = True, logger = True)\n",
    "        return loss\n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        epoch_mean = torch.stack(self.validation_step_outputs).mean()\n",
    "        epoch_auroc = torch.stack(self.validation_auroc).mean()\n",
    "        epoch_acc = torch.stack(self.validation_acc).mean()\n",
    "        self.vloss.append(float(epoch_mean.detach().cpu().numpy()))\n",
    "        self.vauroc.append(float(epoch_auroc.detach().cpu().numpy()))\n",
    "        self.vacc.append(float(epoch_acc.detach().cpu().numpy()))\n",
    "        self.validation_step_outputs.clear()\n",
    "        self.validation_auroc.clear()\n",
    "        self.validation_acc.clear()\n",
    "    \n",
    "    def test_step(self, batch, batch_index):\n",
    "        loss, out, y = self._common_step(batch, batch_index)\n",
    "        pred = self.softmax(out)\n",
    "        t_auroc = auroc(pred, y, task = 'multiclass', num_classes = self.config['n_labels'])\n",
    "        t_acc = accuracy(pred, y, task = 'multiclass', num_classes = self.config['n_labels'])\n",
    "        self.test_step_outputs.append(loss)\n",
    "        self.test_auroc.append(t_auroc)\n",
    "        self.test_acc.append(t_acc)\n",
    "        self.log(\"Test Accuracy\", t_acc, prog_bar = True, logger = True)\n",
    "        return loss\n",
    "\n",
    "    def predict_step(self, batch, batch_index):\n",
    "        loss, out, y = self._common_step(batch, batch_index)\n",
    "        return loss\n",
    "    \n",
    "    def _common_step(self, batch, batch_index):\n",
    "        img = batch['image']\n",
    "        text = batch['input_ids']\n",
    "        attn_mask = batch['attention_mask']\n",
    "        y = batch['labels']\n",
    "        y = y.type(torch.LongTensor)\n",
    "        y = y.to(config['device'])\n",
    "        img = img.type(torch.cuda.FloatTensor)\n",
    "        out = self.forward(img, text, attn_mask)\n",
    "        loss = self.loss(out, y)\n",
    "        return loss, out, y\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr = self.config['lr'])\n",
    "        return [optimizer]\n",
    "    \n",
    "    def plot_loss(self):\n",
    "        self.vloss.pop()\n",
    "        plt.plot(self.tloss, label = 'Training')\n",
    "        plt.plot(self.vloss, label = 'Validation')\n",
    "        plt.title('Loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    def plot_auroc(self):\n",
    "        self.vauroc.pop()\n",
    "        plt.plot(self.tauroc, label = 'Training')\n",
    "        plt.plot(self.vauroc, label = 'Validation')\n",
    "        plt.title('AUROC')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    def plot_accuracy(self):\n",
    "        self.vacc.pop()\n",
    "        plt.plot(self.tacc, label = 'Training')\n",
    "        plt.plot(self.vacc, label = 'Validation')\n",
    "        plt.title('Accuracy')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7a5045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datamodule\n",
    "if config['reload'] == True:\n",
    "    memes = Load_Memes(config)\n",
    "    memes_data_module = Memes_Data_Module(*memes, batch_size = config['batch_size'], text_model = config['tmodel_name'])\n",
    "else:\n",
    "    img_train = torch.load('img_train20.pt')\n",
    "    train_label = pd.read_csv('labels_train20.csv')\n",
    "    val_data = torch.load('img_val20.pt')\n",
    "    val_label = pd.read_csv('labels_val20.csv')\n",
    "    \n",
    "    \n",
    "    img_data_module = Images_Data_Module(train_data, train_label, val_data, val_label, batch_size = config['batch_size'])\n",
    "\n",
    "# model\n",
    "model = CVT_Roberta(config)\n",
    "\n",
    "# trainer and fit\n",
    "trainer = pl.Trainer(max_epochs = config['n_epochs'], devices = 1, accelerator = \"gpu\", num_sanity_val_steps = 0)\n",
    "trainer.fit(model, memes_data_module)\n",
    "trainer.validate(model, memes_data_module)\n",
    "trainer.test(model, memes_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f878fd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e5114b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_auroc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd708dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_accuracy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
